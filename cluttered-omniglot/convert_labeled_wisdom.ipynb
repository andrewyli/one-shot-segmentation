{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting object-labeled wisdom dataset to cluttered omniglot format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import mkdir_if_missing\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input directories\n",
    "AMODAL_MASK_DIR = \"/nfs/diskstation/dmwang/labeled_wisdom_real/dataset\"\n",
    "SCENE_DIR = \"/nfs/diskstation/dmwang/labeled_wisdom_real/phoxi/depth_ims\"\n",
    "JSON_DIR = \"/nfs/diskstation/dmwang/labeled_wisdom_real/phoxi/color_ims\"\n",
    "MASK_DIR = \"/nfs/diskstation/dmwang/labeled_wisdom_real/phoxi/modal_segmasks\"\n",
    "\n",
    "# output directories\n",
    "OUT_DIR = \"/nfs/diskstation/projects/dex-net/segmentation/datasets/mask-net-real/fold_0000\"\n",
    "mkdir_if_missing(OUT_DIR)\n",
    "mkdir_if_missing(os.path.join(OUT_DIR, \"train\"))\n",
    "mkdir_if_missing(os.path.join(OUT_DIR, \"val-train\"))\n",
    "mkdir_if_missing(os.path.join(OUT_DIR, \"val-one-shot\"))\n",
    "mkdir_if_missing(os.path.join(OUT_DIR, \"test-train\"))\n",
    "mkdir_if_missing(os.path.join(OUT_DIR, \"test-one-shot\"))\n",
    "\n",
    "# real dataset parameters\n",
    "NUM_IMS = 400\n",
    "\n",
    "# original image shape\n",
    "IM_WIDTH = 772\n",
    "IM_HEIGHT = 1032\n",
    "\n",
    "\n",
    "# 1:3 ratio between im_size and tar_size\n",
    "IM_SIZE = 384\n",
    "TAR_SIZE = 128\n",
    "\n",
    "# Image distortion\n",
    "ANGLE = 100\n",
    "SHEAR = 4\n",
    "\n",
    "# For storage purposes\n",
    "BLOCK_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_x(phi, theta, ptx, pty):\n",
    "    return np.cos(phi+theta)*ptx + np.sin(phi-theta)*pty\n",
    "\n",
    "\n",
    "def rot_y(phi, theta, ptx, pty):\n",
    "    return -np.sin(phi+theta)*ptx + np.cos(phi-theta)*pty\n",
    "\n",
    "\n",
    "def prepare_img(img, angle=100, shear=2.5, scale=2):\n",
    "    # Apply affine transformations and scale characters for data augmentation\n",
    "    phi = np.radians(np.random.uniform(-angle, angle))\n",
    "    theta = np.radians(np.random.uniform(-shear, shear))\n",
    "    a = scale**np.random.uniform(-1, 1)\n",
    "    b = scale**np.random.uniform(-1, 1)\n",
    "    (x, y) = img.shape\n",
    "    x = a * x\n",
    "    y = b * y\n",
    "    xextremes = [rot_x(phi, theta, 0, 0), rot_x(phi, theta, 0, y), rot_x(phi, theta, x, 0), rot_x(phi, theta, x, y)]\n",
    "    yextremes = [rot_y(phi, theta, 0, 0), rot_y(phi, theta, 0, y), rot_y(phi, theta, x, 0), rot_y(phi, theta, x, y)]\n",
    "    mnx = min(xextremes)\n",
    "    mxx = max(xextremes)\n",
    "    mny = min(yextremes)\n",
    "    mxy = max(yextremes)\n",
    "\n",
    "    aff_bas = np.array([[a*np.cos(phi+theta), b*np.sin(phi-theta), -mnx], [-a*np.sin(phi+theta), b*np.cos(phi-theta), -mny], [0, 0, 1]])\n",
    "    aff_prm = np.linalg.inv(aff_bas)\n",
    "    pil_img = Image.fromarray(img)\n",
    "    pil_img = pil_img.transform((int(mxx - mnx),int(mxy - mny)),\n",
    "                                    method=Image.AFFINE,\n",
    "                                    data=np.ndarray.flatten(aff_prm[0:2, :]))\n",
    "    pil_img = pil_img.resize((int(TAR_SIZE * (mxx - mnx) / 100), int(TAR_SIZE * (mxy - mny) / 100)))\n",
    "\n",
    "    return np.array(pil_img)\n",
    "\n",
    "\n",
    "def bbox(im):\n",
    "    # get bounding box coordinates\n",
    "    rows = np.any(im, axis=1)\n",
    "    cols = np.any(im, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "\n",
    "def make_target(modal_mask, angle=0, shear=0, scale=1):\n",
    "    # make target image\n",
    "    transformed_mask = prepare_img(modal_mask, angle, shear, scale)\n",
    "    top, bot, left, right = bbox(transformed_mask)\n",
    "    obj_size = max(bot - top, right - left)\n",
    "    margin = max((TAR_SIZE * 2 - obj_size) // 2, 0)\n",
    "    return cv2.resize(\n",
    "        transformed_mask[max(0, top - margin):min(transformed_mask.shape[0], bot + margin),\n",
    "                         max(0, left - margin):min(transformed_mask.shape[1], right + margin)],\n",
    "        (TAR_SIZE, TAR_SIZE),\n",
    "        interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def resize_scene(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = np.pad(im, (((IM_WIDTH - IM_SIZE) // 2, (IM_WIDTH - IM_SIZE) // 2), (0, 0)), mode=\"constant\")\n",
    "    elif len(im.shape) == 3:\n",
    "        im = np.pad(im, (((IM_WIDTH - IM_SIZE) // 2, (IM_WIDTH - IM_SIZE) // 2), (0, 0), (0, 0)), mode=\"constant\")\n",
    "    else:\n",
    "        raise Exception(\"image dimensions not valid for scene/ground truth, shape: {}\".format(im.shape))\n",
    "    return cv2.resize(\n",
    "        im,\n",
    "        (IM_SIZE, IM_SIZE),\n",
    "        interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/12000 [01:17<4:32:27,  1.36s/it] "
     ]
    }
   ],
   "source": [
    "# Looping through all image indices\n",
    "#   Looping through all labels in the json list\n",
    "#     Get the name\n",
    "#     Get the target file corresponding to the name\n",
    "#     Add the image to the batch\n",
    "#     Process the segmask from modal_segmasks\n",
    "\n",
    "data_count = 0\n",
    "for meta_idx in tqdm(range(NUM_IMS * 30)):\n",
    "    idx = meta_idx % NUM_IMS\n",
    "    f = open(os.path.join(JSON_DIR, \"image_{:06d}.json\".format(idx)))\n",
    "    json_file = json.load(f)\n",
    "    scene_path = os.path.join(SCENE_DIR, \"image_{:06d}.png\".format(idx))\n",
    "    mask_path = os.path.join(MASK_DIR, \"image_{:06d}.png\".format(idx))\n",
    "\n",
    "    # read and blockify scene\n",
    "    scene_im = io.imread(scene_path)\n",
    "    scene_im = resize_scene(scene_im)\n",
    "    scene_im = np.expand_dims(scene_im, axis=0)\n",
    "    \n",
    "    # for modal masks\n",
    "    joint_mask = io.imread(mask_path)\n",
    "    for label in json_file[\"labels\"]:\n",
    "        target_name = label[\"label_class\"]\n",
    "        target_id = label[\"object_id\"]\n",
    "        target_path = os.path.join(AMODAL_MASK_DIR, \n",
    "                                   \"image_{:06d}\".format(idx), \n",
    "                                   \"{}.png\".format(target_name))\n",
    "        try:\n",
    "            target_im = io.imread(target_path)\n",
    "            amodal_mask = make_target(target_im[...,0], angle=0, shear=0)\n",
    "            \"\"\"print(np.unique(amodal_mask))\n",
    "            plt.imshow(amodal_mask)\n",
    "            plt.show()\"\"\"\n",
    "            amodal_mask[amodal_mask > 0] = 1\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        modal_mask = np.copy(joint_mask)\n",
    "        modal_mask[modal_mask != target_id] = 0\n",
    "        modal_mask = resize_scene(modal_mask)\n",
    "        modal_mask[modal_mask > 0] = 1\n",
    "        data_count += 1\n",
    "\n",
    "        \"\"\"plt.imshow(scene_im[0])\n",
    "        plt.show()\n",
    "        plt.imshow(modal_mask)\n",
    "        plt.show()\n",
    "        plt.imshow(amodal_mask)\n",
    "        plt.show()\"\"\"\n",
    "        \n",
    "        # triplicate the amodal mask (128, 128) --> (128, 128, 3)\n",
    "        amodal_mask = np.stack([amodal_mask, amodal_mask, amodal_mask], axis=2)\n",
    " \n",
    "        \n",
    "        # create 1-sized blocks\n",
    "        amodal_mask = np.expand_dims(amodal_mask, axis=0)\n",
    "        modal_mask = np.expand_dims(modal_mask, axis=2)\n",
    "        modal_mask = np.expand_dims(modal_mask, axis=0)\n",
    "        \n",
    "        \"\"\"print(modal_mask.shape)\n",
    "        print(amodal_mask.shape)\n",
    "        print(scene_im.shape)\"\"\"\n",
    "        \n",
    "        np.save(os.path.join(\n",
    "            OUT_DIR,\n",
    "            \"test-train/\",\n",
    "            \"image_{:08d}.npy\".format(meta_idx)),\n",
    "               scene_im)\n",
    "        np.save(os.path.join(\n",
    "            OUT_DIR,\n",
    "            \"test-train/\",\n",
    "            \"segmentation_{:08d}.npy\".format(meta_idx)),\n",
    "               modal_mask)\n",
    "        np.save(os.path.join(\n",
    "            OUT_DIR,\n",
    "            \"test-train/\",\n",
    "            \"target_{:08d}.npy\".format(meta_idx)),\n",
    "               amodal_mask)\n",
    "        np.save(os.path.join(\n",
    "            OUT_DIR,\n",
    "            \"test-one-shot/\",\n",
    "            \"image_{:08d}.npy\".format(meta_idx)),\n",
    "               scene_im)\n",
    "        np.save(os.path.join(\n",
    "            OUT_DIR,\n",
    "            \"test-one-shot/\",\n",
    "            \"segmentation_{:08d}.npy\".format(meta_idx)),\n",
    "               modal_mask)\n",
    "        np.save(os.path.join(\n",
    "            OUT_DIR,\n",
    "            \"test-one-shot/\",\n",
    "            \"target_{:08d}.npy\".format(meta_idx)),\n",
    "               amodal_mask)        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = np.copy(im)\n",
    "im2[im2 != 1] = 0\n",
    "print(im2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
